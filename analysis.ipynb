{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38332bitf61978c659e34062ad29b2c1a667dcdd",
   "display_name": "Python 3.8.3 32-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%%pycodestyle\n",
    "# https://stackoverflow.com/a/54278757\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "weo_subject_code = 'WEO Subject Code'\n",
    "estimates_after = 'Estimates Start After'\n",
    "iso_col = 'ISO'\n",
    "country_name = 'Country'\n",
    "usecols = [iso_col, weo_subject_code, country_name]\n",
    "for i in range(1980,2020):\n",
    "    usecols.append(str(i))\n",
    "usecols.append(estimates_after)\n",
    "\n",
    "df = pd.read_table(\n",
    "    'WEOOct2020all.xls',\n",
    "    encoding='UTF-16-LE',\n",
    "    usecols=usecols,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' select top 10 GDP per capita countries '''\n",
    "\n",
    "# filtering gdp per capita \n",
    "gdppc = 'NGDPRPPPPC'\n",
    "gdp_per_capita_common_dollar = lambda col: col[weo_subject_code] == gdppc\n",
    "gdp_per_capita_df = df.loc[gdp_per_capita_common_dollar]\n",
    "\n",
    "# https://stackoverflow.com/a/52065957\n",
    "#gdp_per_capita_df = gdp_per_capita_df['2019'].astype('str').str.replace(',','')\n",
    "\n",
    "# creating dataframe for sorting\n",
    "# https://stackoverflow.com/a/57064872\n",
    "year_col = '2019'\n",
    "year_col_before = str(int(year_col)-1)\n",
    "gdp_increase_col = f'GDP Increase from {year_col_before} to {year_col}'\n",
    "\n",
    "# requires converting to numeric value for sorting\n",
    "gdp_per_capita_df[year_col] = gdp_per_capita_df[year_col].replace(regex=',',value='').astype(float)\n",
    "gdp_per_capita_df[year_col_before] = gdp_per_capita_df[year_col_before].replace(regex=',',value='').astype(float)\n",
    "gdp_per_capita_df = gdp_per_capita_df[[country_name, year_col, year_col_before]]\n",
    "gdp_per_capita_df = gdp_per_capita_df.set_index(country_name)\n",
    "\n",
    "# calculate difference between two columns row by row\n",
    "# https://towardsdatascience.com/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1\n",
    "#gdp_per_capita_df.loc[:,gdp_increase_col] = gdp_per_capita_df.loc[:,year_col_before].diff()\n",
    "#gdp_per_capita_df[gdp_increase_col] = gdp_per_capita_df[year_col] - gdp_per_capita_df[year_col]\n",
    "\n",
    "# ran into issues that calculation showed zeros every where\n",
    "# lost datatype :/\n",
    "c = []\n",
    "for row in gdp_per_capita_df.itertuples():\n",
    "   #c.append([row[Index], row[year_col], row[year_col_before], row[year_col] - row[year_col_before]])\n",
    "   c.append([row[0], row[1], row[2], row[1] - row[2]])\n",
    "\n",
    "delta_col = np.array(c)\n",
    "delta_df = pd.DataFrame(delta_col, columns=[country_name, year_col, year_col_before, gdp_increase_col])\n",
    "delta_df = delta_df.set_index(country_name).astype(float)\n",
    "delta_df = delta_df.dropna()\n",
    "\n",
    "# sorting on gdp increase col\n",
    "delta_df = delta_df.sort_values(gdp_increase_col, ascending=False, na_position='last')\n",
    "\n",
    "# select top 10\n",
    "delta_df[:10]\n",
    "\n",
    "# select first row of column\n",
    "# https://stackoverflow.com/a/25254087\n",
    "#gdp_per_capita_df.iloc[0, gdp_per_capita_df.columns.get_loc(year_col)]\n",
    "\n",
    "# https://stackoverflow.com/a/64307654\n",
    "#df[gdp_per_capita_common_dollar].values\n",
    "# for i, row in enumerate(df[gdp_per_capita_common_dollar].values):\n",
    "#     if row[2] < 1:\n",
    "#         print(i,row)\n",
    "\n",
    "# df_only_iso =  df[gdp_per_capita_common_dollar][iso_col]\n",
    "# df_only_iso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oecd_countries_all_caps = {\n",
    "    'AUSTRIA':'',\n",
    "    'AUSTRALIA':'',\n",
    "    'BELGIUM':'',\n",
    "    'CANADA':'',\n",
    "    'CHILE':'',\n",
    "    'COLOMBIA':'',\n",
    "    'CZECH REPUBLIC':'',\n",
    "    'DENMARK':'',\n",
    "    'ESTONIA':'',\n",
    "    'FINLAND':'',\n",
    "    'FRANCE':'',\n",
    "    'GERMANY':'',\n",
    "    'GREECE':'',\n",
    "    'HUNGARY':'',\n",
    "    'ICELAND':'',\n",
    "    'IRELAND':'',\n",
    "    'ISRAEL':'',\n",
    "    'ITALY':'',\n",
    "    'JAPAN':'',\n",
    "    'KOREA':'',\n",
    "    'LATVIA':'',\n",
    "    'LITHUANIA':'',\n",
    "    'LUXEMBOURG':'',\n",
    "    'MEXICO':'',\n",
    "    'NETHERLANDS':'',\n",
    "    'NEW ZEALAND':'',\n",
    "    'NORWAY':'',\n",
    "    'POLAND':'',\n",
    "    'PORTUGAL':'',\n",
    "    'SLOVAK REPUBLIC':'',\n",
    "    'SLOVENIA':'',\n",
    "    'SPAIN':'',\n",
    "    'SWEDEN':'',\n",
    "    'SWITZERLAND':'',\n",
    "    'TURKEY':'',\n",
    "    'UNITED KINGDOM':'',\n",
    "    'UNITED STATES':''}\n",
    "# properly formatting OECD country names\n",
    "oecd_countries = {}\n",
    "for key in oecd_countries_all_caps:\n",
    "    oecd_countries[key.title()] = ''\n",
    "# oecd_countries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "plot of OECD countries population\n",
    "'''\n",
    "\n",
    "population_key = 'LP'\n",
    "# selecting dataframe based on two columns\n",
    "# population_df = df.loc[ (df[weo_subject_code] == population_key) & (df[country_name] == 'Lithuania')]\n",
    "\n",
    "# creating dataframe on population\n",
    "population_df = df.loc[(df[weo_subject_code] == population_key)]\n",
    "\n",
    "# sets index and index is stored for future\n",
    "population_df = population_df.set_index(country_name)\n",
    "\n",
    "# filtering oecd contries\n",
    "population_df = population_df.loc[oecd_countries]\n",
    "\n",
    "# do not convert to string for filtering\n",
    "# rather convert dataframe to floats\n",
    "decade = []\n",
    "for i in range(2010,2020):\n",
    "    decade.append(str(i))\n",
    "\n",
    "# https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\n",
    "# selecting decade colums\n",
    "population_df = population_df[decade]\n",
    "# converting to plotable time series, transpose\n",
    "population_df = population_df.T\n",
    "\n",
    "# wrong data type is set needs to cast to numeris type\n",
    "population_df = population_df.astype(float)\n",
    "\n",
    "# select only limited subset of countries instead of all as it population change is better visible\n",
    "population_df = population_df[['Lithuania', 'Latvia', 'Iceland']]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "population_df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''save all countries GDP in different PNG files'''\n",
    "\n",
    "# Gross domestic product, current prices\n",
    "# Values are based upon GDP in national currency converted to U.S. dollars\n",
    "gdp_key = 'NGDPD'\n",
    "\n",
    "gdp_df = df.loc[lambda df: df[weo_subject_code] == gdp_key]\n",
    "\n",
    "# setting index country name\n",
    "gdp_df = gdp_df.set_index(country_name)\n",
    "\n",
    "# filtering non required columns\n",
    "selected_cols = []\n",
    "\n",
    "for col in gdp_df.columns:\n",
    "    if col == iso_col or col == weo_subject_code or col == estimates_after:\n",
    "       continue\n",
    "\n",
    "    selected_cols.append(col)\n",
    "\n",
    "# select country name column and period columns\n",
    "gdp_df = gdp_df[selected_cols]\n",
    "\n",
    "# https://stackoverflow.com/a/49896522\n",
    "# applies lambda to rows, cleans numeric values of thousands separator\n",
    "gdp_df = gdp_df.apply(lambda df: df.str.replace(',','').astype(float), axis=0)\n",
    "\n",
    "# prepare folder for pics\n",
    "figure_folder_name = 'figures'\n",
    "import os\n",
    "if not os.path.exists(figure_folder_name):\n",
    "    os.makedirs(figure_folder_name)\n",
    "\n",
    "# remove [0:1] to save all\n",
    "for country in gdp_df.index[0:1]:\n",
    "    # print(country)\n",
    "    # https://stackoverflow.com/a/45379210\n",
    "    fig = gdp_df.loc[country].plot().get_figure()\n",
    "    # https://stackoverflow.com/a/4805178\n",
    "    # if face color is not set explicitly its trasnparet, wtf\n",
    "    fig.savefig(f'{figure_folder_name}\\{country}.png',format='png',transparent=False, facecolor='white')\n",
    "    # closes the plot, as no need to display, while saving\n",
    "    # https://stackoverflow.com/a/15713545\n",
    "    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "source": [
    "''' find lowest common denominator for year 2015 '''\n",
    "# create dataframe of WEO codes and 2015 year\n",
    "common_denominator_df = df[[weo_subject_code,'2015']]\n",
    "\n",
    "# removes all na values\n",
    "common_denominator_df = common_denominator_df.dropna()\n",
    "\n",
    "# selecting only WEO code and grouping to display\n",
    "common_denominator_df = common_denominator_df[[weo_subject_code]]\n",
    "common_denominator_df = common_denominator_df.groupby([weo_subject_code])\n",
    "\n",
    "# common_denominator_df.apply(print)\n",
    "# https://stackoverflow.com/a/36951842\n",
    "# simple print\n",
    "lowest_common_denom = []\n",
    "for key in common_denominator_df.groups.keys():\n",
    "   lowest_common_denom.append(key)\n",
    "\n",
    "# uncoment for display \n",
    "# lowest_common_denom\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' K-Means clustering '''\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# still requires GDP_key\n",
    "volume_of_exported_goods_key = 'TXG_RPCH'\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' GDP per capita prediction '''\n",
    "\n",
    "# select non GDP related weo keys\n",
    "gdp_weo_key = 'GDP'\n",
    "\n",
    "country_select = lambda df: df[country_name]=='Germany'\n",
    "# use regular expr with bitmask to filter out all GDP related fields\n",
    "# https://stackoverflow.com/a/17097777\n",
    "input_features = df[\n",
    "      ~df[weo_subject_code].str.contains(gdp_weo_key, na=False)\n",
    "      & ~df[weo_subject_code].str.contains('PPP', na=False)].fillna(0.0)\n",
    "\n",
    "gdp_per_capita_common_dollar = lambda col: col[weo_subject_code] == gdppc\n",
    "gdppc = 'NGDPRPPPPC'\n",
    "\n",
    "#drop_clumns = [country_name,iso_col, weo_subject_code, estimates_after]\n",
    "def prepare_country_data(input_features, country_select):\n",
    "    drop_clumns = [country_name, iso_col, estimates_after]\n",
    "\n",
    "    input_features = input_features.loc[country_select]\n",
    "    #input_features = input_features.set_index(country_name)\n",
    "    input_features = input_features.drop(columns=drop_clumns)\n",
    "    input_features = input_features.T\n",
    "\n",
    "    # save feature column codes\n",
    "    feature_weo_codes = []\n",
    "\n",
    "    # building feature data frame\n",
    "    cleand_features = []\n",
    "    i = 0\n",
    "    for row in input_features.itertuples():\n",
    "        if len(row) < 21:\n",
    "            continue\n",
    "        # index \n",
    "        if row[0] == weo_subject_code:\n",
    "            feature_weo_codes = row[1:]\n",
    "            continue\n",
    "\n",
    "        float_fts = []\n",
    "        \n",
    "        for x in row[1:]:\n",
    "            \n",
    "            if type(x) == str:\n",
    "                if x == '--':\n",
    "                    float_fts.append(0.0)\n",
    "                else:\n",
    "                    float_fts.append(float(x.replace(',','')))\n",
    "            else:\n",
    "                float_fts.append(float(x))\n",
    "        cleand_features.append(float_fts)\n",
    "\n",
    "    # cleand_features  \n",
    "    # print(feature_weo_codes)\n",
    "\n",
    "    drop_columns_inlcuding_weo = [country_name,iso_col, estimates_after,weo_subject_code]\n",
    "\n",
    "    gdp_data = df.loc[gdp_per_capita_common_dollar].dropna()\n",
    "    gdp_data = gdp_data.loc[country_select].drop(columns=drop_columns_inlcuding_weo)\n",
    "    # gdp_data = gdp_data.apply(lambda df: df.str.replace(',','').astype(float), axis=0)\n",
    "    cleand_result = []\n",
    "    for row in gdp_data.T.itertuples():\n",
    "        if len(row) < 2:\n",
    "            continue\n",
    "\n",
    "        cleand_result.append(float(row[1].replace(',','')))\n",
    "\n",
    "    return (cleand_features, cleand_result, feature_weo_codes)\n",
    "\n",
    "def select_training_countries():\n",
    "    countries_list = input_features[[country_name]]\n",
    "    countries_list = countries_list.set_index(country_name)\n",
    "    countries_list = countries_list.groupby(country_name)\n",
    "    filtered_countries = []\n",
    "    for i, key in enumerate(countries_list.groups.keys()):\n",
    "        if type(key) != str:\n",
    "            continue\n",
    "\n",
    "        if i % 3 == 0 or key == 'Germany' or key == 'Italy':\n",
    "            filtered_countries.append(key)\n",
    "\n",
    "    return filtered_countries\n",
    "\n",
    "failed_result_gen = []\n",
    "cleand_features = []\n",
    "cleand_result = []\n",
    "feature_weo_codes = []\n",
    "for c_name in select_training_countries():\n",
    "    gdp_features, gdp_result, weo_codes = prepare_country_data(\n",
    "        input_features=input_features,\n",
    "        country_select=lambda df: df[country_name]==c_name)\n",
    "    # print(c_name, cleand_features, cleand_result)\n",
    "    if len(gdp_result) < 1:\n",
    "        failed_result_gen.append(c_name)\n",
    "        continue\n",
    "\n",
    "    feature_weo_codes = weo_codes\n",
    "    # append features and results\n",
    "    for row in gdp_features:\n",
    "        cleand_features.append(row)\n",
    "        #print(cleand_features)\n",
    "\n",
    "    for x in gdp_result:\n",
    "        cleand_result.append(x)\n",
    "\n",
    "print(np.array(cleand_features).shape, np.array(cleand_result).shape)\n",
    "# print(failed_result_gen, len(failed_result_gen), len(select_training_countries()))\n",
    "\n",
    "#cleand_result\n",
    "\n",
    "slice_length = -600\n",
    "training_features = cleand_features[:slice_length]\n",
    "training_gdp = cleand_result[:slice_length]\n",
    "\n",
    "training_features_test = cleand_features[slice_length:]\n",
    "training_gdp_test = cleand_result[slice_length:]\n",
    "\n",
    "# training\n",
    "# https://machinelearningmastery.com/make-predictions-scikit-learn/\n",
    "# https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(training_features, training_gdp)\n",
    "\n",
    "def get_filter_coeficients_for_manual_selection():\n",
    "    filter_coefs = []\n",
    "    # # get importance\n",
    "    importance = model.coef_\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance):\n",
    "        #if v > 100:\n",
    "        print_t = (i,v, feature_weo_codes[i])\n",
    "        print('Feature: %0d, Score: %.5f, weo_key: %s' % print_t)\n",
    "        filter_coefs.append(print_t)\n",
    "    # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance))], importance)\n",
    "    plt.show()\n",
    "\n",
    "    return filter_coefs\n",
    "\n",
    "#print(get_filter_coeficients_for_manual_selection())\n",
    "\n",
    "# prediction\n",
    "predict = training_features_test\n",
    "result = training_gdp_test\n",
    "\n",
    "result_predicted = model.predict(predict)\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', model.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(result, result_predicted))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(result, result_predicted))\n",
    "\n",
    "# print('real result: ', result, result_predicted[0])\n",
    "\n",
    "# # https://scikit-learn.org/stable/modules/model_persistence.html\n",
    "# file_name = 'filename.joblib'\n",
    "# dump(model, file_name)\n",
    "# model2 = load(file_name)\n",
    "\n",
    "# result_predicted2 = model2.predict(predict)\n",
    "# print('Coefficients: \\n', model2.coef_\n",
    "#       % mean_squared_error(result, result_predicted2))\n",
    "# print('Coefficient of determination: %.2f'\n",
    "#       % r2_score(result, result_predicted2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' auto feature selection '''\n",
    "# https://machinelearningmastery.com/feature-selection-for-regression-data/\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    # fs = SelectKBest(score_func=f_regression, k='all')\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(training_features, training_gdp, training_features_test)\n",
    "\n",
    "# get selected features\n",
    "# https://stackoverflow.com/a/43765224\n",
    "\n",
    "auto_selected_features = fs.get_support(indices=True)\n",
    "print(auto_selected_features)\n",
    "print(feature_weo_codes)\n",
    "best_features = []\n",
    "for i in auto_selected_features:\n",
    "    best_features.append(feature_weo_codes[i])\n",
    "print(best_features)\n",
    "\n",
    "# fit the model\n",
    "model5 = LinearRegression()\n",
    "model5.fit(X_train_fs, training_gdp)\n",
    "# evaluate the model\n",
    "yhat = model5.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "mse = mean_squared_error(training_gdp_test, yhat)\n",
    "print('MSE: %.2f' % mse)\n",
    "\n",
    "file_name = 'filename5.joblib'\n",
    "dump(model5, file_name)\n",
    "\n",
    "\n",
    "# # shows coefs and plot\n",
    "# print(X_train_fs.shape)\n",
    "# # what are scores for the features\n",
    "# for i in range(len(fs.scores_)):\n",
    "# \tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# # plot the scores\n",
    "# plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "# plt.show()"
   ]
  }
 ]
}